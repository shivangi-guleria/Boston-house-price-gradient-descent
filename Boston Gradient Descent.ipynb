{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(Xtrain,Ytrain, learning_rate, m):\n",
    "\n",
    "    m_slope = np.zeros(14)\n",
    "    \n",
    "    M = len(Xtrain)\n",
    "    for i in range(M):\n",
    "        x=Xtrain[i,:]\n",
    "        y=Ytrain[i]\n",
    "        for j in range(14):\n",
    "            m_slope[j] += (-2/M)* (y - m[j] * x[j] )*x[j]\n",
    "\n",
    "         \n",
    "    new_m = m - learning_rate*m_slope\n",
    "    \n",
    "\n",
    "    return new_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(Xtrain,Ytrain, learning_rate, num_iterations):\n",
    "\n",
    "    m = np.zeros(14)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        m= step_gradient(Xtrain,Ytrain, learning_rate, m )\n",
    "        print(i, \" Cost: \", cost(Xtrain,Ytrain, m))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(Xtrain,Ytrain, m):\n",
    "  \n",
    "    total_cost = 0\n",
    "    M = len(data)\n",
    "    for i in range(M):\n",
    "        x=Xtrain[i,:]\n",
    "        y=Ytrain[i]\n",
    "        for j in range(14):\n",
    "            total_cost += (1/M)*((y - m[j]*x[j])**2)\n",
    "    return total_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(Xtrain,m):\n",
    "\n",
    "    M = len(Xtrain)\n",
    "    yp=np.zeros(M)\n",
    "    for i in range(M):\n",
    "\n",
    "        for j in range(14):\n",
    "             yp[i]+= m[j]*Xtrain[i][j]\n",
    "    \n",
    "    return yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_true,y_pred):\n",
    "    u=((y_true-y_pred)**2).sum()\n",
    "    v=((y_true-y_true.mean())**2).sum()\n",
    "    return 1-u/v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Cost:  8135.2802007106575\n",
      "1  Cost:  8016.448565546043\n",
      "2  Cost:  7931.5215104993085\n",
      "3  Cost:  7879.305790700471\n",
      "4  Cost:  7845.317135357344\n",
      "5  Cost:  7823.601492665553\n",
      "6  Cost:  7809.62812087896\n",
      "7  Cost:  7800.6780307019035\n",
      "8  Cost:  7794.969145721757\n",
      "9  Cost:  7791.365072034924\n",
      "10  Cost:  7789.130569734733\n",
      "11  Cost:  7787.790247064765\n",
      "12  Cost:  7787.03524178332\n",
      "13  Cost:  7786.664289666052\n",
      "14  Cost:  7786.545738683539\n",
      "15  Cost:  7786.593143763054\n",
      "16  Cost:  7786.74950553603\n",
      "17  Cost:  7786.977070509052\n",
      "18  Cost:  7787.250709360967\n",
      "19  Cost:  7787.553605963107\n",
      "20  Cost:  7787.874442092556\n",
      "21  Cost:  7788.205552997293\n",
      "22  Cost:  7788.541714818907\n",
      "23  Cost:  7788.8793444056455\n",
      "24  Cost:  7789.215969064538\n",
      "25  Cost:  7789.5498735598085\n",
      "26  Cost:  7789.879863883462\n",
      "27  Cost:  7790.205108238128\n",
      "28  Cost:  7790.52502927789\n",
      "29  Cost:  7790.839230528525\n",
      "30  Cost:  7791.147445711378\n",
      "31  Cost:  7791.449503499809\n",
      "32  Cost:  7791.745302738992\n",
      "33  Cost:  7792.034794809871\n",
      "34  Cost:  7792.317970909757\n",
      "35  Cost:  7792.594852746692\n",
      "36  Cost:  7792.865485627321\n",
      "37  Cost:  7793.129933243422\n",
      "38  Cost:  7793.388273676343\n",
      "39  Cost:  7793.640596289067\n",
      "40  Cost:  7793.886999271915\n",
      "41  Cost:  7794.12758767934\n",
      "42  Cost:  7794.362471839721\n",
      "43  Cost:  7794.59176605335\n",
      "44  Cost:  7794.8155875176535\n",
      "45  Cost:  7795.034055432023\n",
      "46  Cost:  7795.247290249145\n",
      "47  Cost:  7795.455413045619\n",
      "48  Cost:  7795.658544990607\n",
      "49  Cost:  7795.856806898293\n",
      "50  Cost:  7796.050318848939\n",
      "51  Cost:  7796.239199869757\n",
      "52  Cost:  7796.423567666237\n",
      "53  Cost:  7796.603538396947\n",
      "54  Cost:  7796.779226485888\n",
      "55  Cost:  7796.950744467441\n",
      "56  Cost:  7797.118202859337\n",
      "57  Cost:  7797.281710060248\n",
      "58  Cost:  7797.441372268848\n",
      "59  Cost:  7797.597293421081\n",
      "60  Cost:  7797.749575143947\n",
      "61  Cost:  7797.898316723236\n",
      "62  Cost:  7798.043615083495\n",
      "63  Cost:  7798.185564778669\n",
      "64  Cost:  7798.32425799187\n",
      "65  Cost:  7798.459784543249\n",
      "66  Cost:  7798.59223190476\n",
      "67  Cost:  7798.721685220672\n",
      "68  Cost:  7798.848227333178\n",
      "69  Cost:  7798.971938812597\n",
      "70  Cost:  7799.092897990701\n",
      "71  Cost:  7799.21118099763\n",
      "72  Cost:  7799.326861800825\n",
      "73  Cost:  7799.440012246594\n",
      "74  Cost:  7799.550702102724\n",
      "75  Cost:  7799.658999103089\n",
      "76  Cost:  7799.7649689925665\n",
      "77  Cost:  7799.86867557334\n",
      "78  Cost:  7799.970180751146\n",
      "79  Cost:  7800.069544582092\n",
      "80  Cost:  7800.166825319668\n",
      "81  Cost:  7800.262079461217\n",
      "82  Cost:  7800.355361794772\n",
      "83  Cost:  7800.446725445027\n",
      "84  Cost:  7800.536221919395\n",
      "85  Cost:  7800.623901153048\n",
      "86  Cost:  7800.7098115536155\n",
      "87  Cost:  7800.794000045204\n",
      "88  Cost:  7800.876512111631\n",
      "89  Cost:  7800.957391838765\n",
      "90  Cost:  7801.0366819563\n",
      "91  Cost:  7801.114423878527\n",
      "92  Cost:  7801.19065774415\n",
      "93  Cost:  7801.265422455502\n",
      "94  Cost:  7801.338755716469\n",
      "95  Cost:  7801.410694069934\n",
      "96  Cost:  7801.481272933795\n",
      "97  Cost:  7801.550526636526\n",
      "98  Cost:  7801.618488451726\n",
      "99  Cost:  7801.685190631278\n",
      "\n",
      "Score of data:  0.7326652388328675\n",
      "\n",
      " [-0.90051104  0.64287018 -0.19897574  0.80261929 -2.074187    2.39808369\n",
      "  0.09589923 -2.89692884  2.04545911 -1.16137088 -2.22232068  0.58090393\n",
      " -4.25472607 22.67681783]\n"
     ]
    }
   ],
   "source": [
    "data=np.loadtxt(r\"C:\\Users\\SHIVANGI\\Desktop\\Machine Learning Coding Ninjas\\10. Project Gradient Descent\\boston dataset\\0000000000002417_training_boston_x_y_train.csv\",delimiter=',')\n",
    "learning_rate = 0.099\n",
    "num_iterations = 100\n",
    "\n",
    "Xtrain=data[:,0:13]\n",
    "Ytrain=data[:,13]\n",
    "\n",
    "z = np.ones((len(Xtrain),1))\n",
    "Xtrain=np.append(Xtrain, z, axis=1)                   #to add column of ones at x[:,13] \n",
    "\n",
    "m= gd(Xtrain,Ytrain, learning_rate, num_iterations)   # c = last column of m i.e m[13]\n",
    "y_pred=predict(Xtrain,m)\n",
    "\n",
    "print(\"\\nScore of data: \",score(Ytrain,y_pred))\n",
    "print(\"\\n\",m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=np.loadtxt(r\"C:\\Users\\SHIVANGI\\Desktop\\Machine Learning Coding Ninjas\\10. Project Gradient Descent\\boston dataset\\0000000000002417_test_boston_x_test.csv\",delimiter=',')\n",
    "\n",
    "\n",
    "x_final=data_test[:,0:13]\n",
    "\n",
    "z = np.ones((len(x_final),1))\n",
    "x_final=np.append(x_final, z, axis=1)\n",
    "\n",
    "y_pred_final=predict(x_final,m)\n",
    "\n",
    "np.savetxt(\"boston_gd_pred.csv\",y_pred_final,fmt='%1.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
